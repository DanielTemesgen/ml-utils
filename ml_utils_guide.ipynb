{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml-utils guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import py_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function below gives us the ability to hide code cells in jupyter notebook. <br>\n",
    "This can be helpful when presenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show=false; \n",
       "    function code_toggle() {\n",
       "     if (code_show){\n",
       "     $('div.input').hide();\n",
       "     } else {\n",
       "     $('div.input').show();\n",
       "     }\n",
       "     code_show = !code_show\n",
       "    } \n",
       "    $( document ).ready(code_toggle);\n",
       "    </script>\n",
       "    The code for this jupyter notebook has been hidden by default for easier reading.\n",
       "    To toggle on/off the code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "py_utils.hide_code_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore how to use the model utils let's quickly make a test model. <br>\n",
    "Firstly, import some more packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification, load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a fake numeric dataset for the purpose of our examples.\n",
    "\n",
    "We'll do this by using scikit-learn's helpful `make_classification` function.\n",
    "\n",
    "<mark>You can 'unpack' arguments into a function via a dictionary using the `**` notation (see below).</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_classification_dict = {'n_samples': 100000, 'n_features': 50}\n",
    "\n",
    "sample_data =  make_classification(**make_classification_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.365997</td>\n",
       "      <td>-0.433317</td>\n",
       "      <td>1.560637</td>\n",
       "      <td>-0.138079</td>\n",
       "      <td>0.245504</td>\n",
       "      <td>0.132429</td>\n",
       "      <td>-0.129720</td>\n",
       "      <td>0.440637</td>\n",
       "      <td>0.876539</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177584</td>\n",
       "      <td>-0.168598</td>\n",
       "      <td>-0.095449</td>\n",
       "      <td>-0.061516</td>\n",
       "      <td>-0.979664</td>\n",
       "      <td>0.558874</td>\n",
       "      <td>-2.092906</td>\n",
       "      <td>0.171905</td>\n",
       "      <td>1.035650</td>\n",
       "      <td>0.430578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.132642</td>\n",
       "      <td>1.886500</td>\n",
       "      <td>-0.378027</td>\n",
       "      <td>1.321950</td>\n",
       "      <td>1.468235</td>\n",
       "      <td>0.851140</td>\n",
       "      <td>0.273501</td>\n",
       "      <td>-1.474592</td>\n",
       "      <td>0.194993</td>\n",
       "      <td>1.007090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720932</td>\n",
       "      <td>-1.619365</td>\n",
       "      <td>0.302415</td>\n",
       "      <td>0.094322</td>\n",
       "      <td>1.447754</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.430696</td>\n",
       "      <td>0.958248</td>\n",
       "      <td>-0.311300</td>\n",
       "      <td>-0.544773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.060272</td>\n",
       "      <td>-1.198590</td>\n",
       "      <td>0.148687</td>\n",
       "      <td>1.467177</td>\n",
       "      <td>0.023818</td>\n",
       "      <td>-0.467987</td>\n",
       "      <td>0.074374</td>\n",
       "      <td>0.248414</td>\n",
       "      <td>-2.211274</td>\n",
       "      <td>1.507540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568848</td>\n",
       "      <td>-0.693858</td>\n",
       "      <td>0.549049</td>\n",
       "      <td>-0.124684</td>\n",
       "      <td>-0.530048</td>\n",
       "      <td>1.417760</td>\n",
       "      <td>-0.609569</td>\n",
       "      <td>-0.026135</td>\n",
       "      <td>-1.037186</td>\n",
       "      <td>-0.623432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.771197</td>\n",
       "      <td>-0.865145</td>\n",
       "      <td>0.607501</td>\n",
       "      <td>-0.910828</td>\n",
       "      <td>-0.556104</td>\n",
       "      <td>-0.987186</td>\n",
       "      <td>0.076289</td>\n",
       "      <td>0.270997</td>\n",
       "      <td>-0.490540</td>\n",
       "      <td>1.691022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.589941</td>\n",
       "      <td>-1.192576</td>\n",
       "      <td>1.390384</td>\n",
       "      <td>-1.842150</td>\n",
       "      <td>0.079264</td>\n",
       "      <td>0.868303</td>\n",
       "      <td>0.309218</td>\n",
       "      <td>-1.786201</td>\n",
       "      <td>1.454674</td>\n",
       "      <td>-0.281275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416671</td>\n",
       "      <td>-0.356968</td>\n",
       "      <td>-0.740395</td>\n",
       "      <td>2.274168</td>\n",
       "      <td>1.440758</td>\n",
       "      <td>-0.367331</td>\n",
       "      <td>-0.736580</td>\n",
       "      <td>-0.118942</td>\n",
       "      <td>-0.845161</td>\n",
       "      <td>-0.014380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109576</td>\n",
       "      <td>-0.877958</td>\n",
       "      <td>0.788034</td>\n",
       "      <td>1.718997</td>\n",
       "      <td>-0.671951</td>\n",
       "      <td>-1.693619</td>\n",
       "      <td>1.327838</td>\n",
       "      <td>-1.463735</td>\n",
       "      <td>-0.217258</td>\n",
       "      <td>0.747213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.365997 -0.433317  1.560637 -0.138079  0.245504  0.132429 -0.129720   \n",
       "1 -0.132642  1.886500 -0.378027  1.321950  1.468235  0.851140  0.273501   \n",
       "2 -1.060272 -1.198590  0.148687  1.467177  0.023818 -0.467987  0.074374   \n",
       "3 -0.771197 -0.865145  0.607501 -0.910828 -0.556104 -0.987186  0.076289   \n",
       "4 -0.416671 -0.356968 -0.740395  2.274168  1.440758 -0.367331 -0.736580   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0  0.440637  0.876539 -0.008592  ...  0.177584 -0.168598 -0.095449 -0.061516   \n",
       "1 -1.474592  0.194993  1.007090  ...  0.720932 -1.619365  0.302415  0.094322   \n",
       "2  0.248414 -2.211274  1.507540  ...  0.568848 -0.693858  0.549049 -0.124684   \n",
       "3  0.270997 -0.490540  1.691022  ... -0.589941 -1.192576  1.390384 -1.842150   \n",
       "4 -0.118942 -0.845161 -0.014380  ... -0.109576 -0.877958  0.788034  1.718997   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0 -0.979664  0.558874 -2.092906  0.171905  1.035650  0.430578  \n",
       "1  1.447754  0.240620  0.430696  0.958248 -0.311300 -0.544773  \n",
       "2 -0.530048  1.417760 -0.609569 -0.026135 -1.037186 -0.623432  \n",
       "3  0.079264  0.868303  0.309218 -1.786201  1.454674 -0.281275  \n",
       "4 -0.671951 -1.693619  1.327838 -1.463735 -0.217258  0.747213  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(sample_data[0])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our y: <br>\n",
    "<mark>You can continue code onto the next line with `\\` (see below)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  0\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(sample_data[1])\\\n",
    ".to_frame()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() #we instantiate the scaler object\n",
    "X_train_scaled = scaler.fit_transform(X_train) #we fit and transform X into the scaler object using .fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's say we want to apply a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85548"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model, the function assumes that we have a 'Models' subfolder so we have one created here. <br>\n",
    "We need to define the following things for this function:\n",
    "* `model_name` = the root name of the model we want to save.\n",
    "* `model_var` = the model variable we want to save.\n",
    "* `subfolder` = optional subfolder we want to use, we don't need it here so let's leave it as an empty string.\n",
    "* `wd` = working directory, the main working directory of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_utils.dump_diff_model(model_name='my_model', model_var=logreg, subfolder='', wd = os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this file, which is saved below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_2019-07-22 01:13:59.555809.joblib']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in os.listdir(os.path.join(os.getcwd(), 'Models')) if x.endswith('.joblib')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and save it again and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_utils.dump_diff_model(model_name='my_model', model_var=logreg, subfolder='', wd = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_2019-07-22 01:13:59.555809.joblib']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in os.listdir(os.path.join(os.getcwd(), 'Models')) if x.endswith('.joblib')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that nothing has saved! <br>\n",
    "This is because we are trying to save the same model twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and save a different model with the same name 'my_model'. <br>\n",
    "Let's say we want to change Logistic Regression solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='saga')\n",
    "logreg.fit(X_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85548"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now changed the solver from 'lbfgs' to 'saga', now let's try and save this different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_utils.dump_diff_model(model_name='my_model', model_var=logreg, subfolder='', wd = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_2019-07-22 01:14:01.120734.joblib',\n",
       " 'my_model_2019-07-22 01:13:59.555809.joblib']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in os.listdir(os.path.join(os.getcwd(), 'Models')) if x.endswith('.joblib')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this new model has been saved. <br>\n",
    "This is because it is different from the most recent version of that model as defined by its timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to save models, let's see how we load them. <br>\n",
    "First let's import out necessary package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use another one of these util functions: most_recent_model() <br>\n",
    "Very simply, it returns the path of the most recent model in a directory (based on the timestamp).\n",
    "\n",
    "Let's see what we define for this function:\n",
    "* `model_name` = the root name of the model we want to save.\n",
    "* `wd` = working directory, the main working directory of our project.\n",
    "* `subfolder` = optional subfolder we want to use, we don't need it here so let's leave it as an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Daniel/Desktop/GitHub_Repos/ml-utils/Models/my_model_2019-07-22 01:14:01.120734.joblib'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_load = py_utils.most_recent_model(model_name = 'my_model', wd = os.getcwd(), subfolder='')\n",
    "model_to_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the path above. <br>\n",
    "Now let's import this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = joblib.load(model_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that we successfully imported this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Default]",
   "language": "python",
   "name": "conda-env-Default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
